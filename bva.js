var shown = {
  "pathMin": 0,
  "pathMax": 0
}

  var datah = [

        {
          "valx": 1,
          "path":0,
          "valy" : 1,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 1,
          "path":0,
          "valy" : 2,
          "tLabel":"",
          "desc":"seelect ",
          "value": 1
        },
        {
          "valx": 1,
          "path":0,
          "valy" : 3,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 1,
          "path":0.1,
          "valy" : 4,
          "tLabel":"Retina",
          "desc":"Light first enters the eye through the cornea and strikes the <strong>retina</strong>, beginning the phototransduction process of turning external light energy into electrical energy. Rod cells (for color perception) and cone cells (for value perception) on the retina absorb the light using rhodopsin proteins to hyperpolarize the cells’ internal charge. Sharpness of perceived images is maintained by concentrating rod cells at the fovea in the back of the eye. Additionally, a background layer of cells, the pigmented epithelium, absorbs unprocessed light. The electrical signals are then converted to glutaminergic messages passed to bipolar, then ganglion cells. Horizontal and amacrine cells act as mediators between each respective layer of transmission to further sharpen the image. These mediators work on the principle that retinal cells are organized in concentric receptive fields, creating a map of “on” and “off” center cells, becoming active depending on their relative positions. The mediators horizontally cancel noise, amplifying these place field maps. From there, downstream ganglion cells themselves are divided into groups of either m- or p-cells, providing unique information to later on dorsal and ventral streams. From there, the neural image travels down the optic nerve, past the chiasm where the images from each receptive field (right and left) are directed to their respective hemispheres. <a href='http://web.csulb.edu/~cwallis/482/visualsystem/eye.html'> More info</a> ",
          "value": 3
        },
        {
          "valx": 1,
          "path":0,
          "valy" : 5,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },

       {
          "valx": 2,
          "path":0,
          "valy" : 1,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 2,
          "path":0,
          "valy" : 2,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 2,
          "path":0,
          "valy" : 3,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 2,
          "path":0,
          "valy" : 4,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 2,
          "path":0,
          "valy" : 5,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },

        {
          "valx": 3,
          "path":0,
          "valy" : 1,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 3,
          "path":0,
          "valy" : 2,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 3,
          "path":0,
          "valy" : 3,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 3,
          "path":0,
          "valy" : 4,
          "tLabel":"",
          "desc":"Interacting with multiple areas in the limbic system, the <strong>PFC</strong> (prefrontal cortex) manages emotional responses by modulating decision-making and attention. It can act directly upon areas such as the NAc to suppress emotional reactions. However, the PFC is suppressed by chronic exposure to stress hormone, leading to reduced thoughtful judgement, which can lead to impulsive behaviors. It is also important to note that the PFC has several subdivisions with unique functions. Particularly important for perception is the orbitofrontal cortex, which is activated when pleasing images are viewed. This suggests a role in aesthetic judgement that is more cognitively complex and goes beyond simple limbic reactions.<a href='https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0021852'> More info</a> ",
          "value": 7
        },
        {
          "valx": 3,
          "path":7,
          "valy" : 5,
          "tLabel":"PFC",
          "desc":"Interacting with multiple areas in the limbic system, the <strong>PFC</strong> (prefrontal cortex) manages emotional responses by modulating decision-making and attention. It can act directly upon areas such as the NAc to suppress emotional reactions. However, the PFC is suppressed by chronic exposure to stress hormone, leading to reduced thoughtful judgement, which can lead to impulsive behaviors. It is also important to note that the PFC has several subdivisions with unique functions. Particularly important for perception is the orbitofrontal cortex, which is activated when pleasing images are viewed. This suggests a role in aesthetic judgement that is more cognitively complex and goes beyond simple limbic reactions.<a href='https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0021852'> More info</a> ",
          "value": 7
        },

        {
          "valx": 4,
          "path":0,
          "valy" : 1,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 4,
          "path":0,
          "valy" : 2,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 4,
          "path":0,
          "valy" : 3,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 7
        },
        {
          "valx": 4,
          "path":0,
          "valy" : 4,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 7
        },
        {
          "valx": 4,
          "path":0,
          "valy" : 5,
          "tLabel":"",
          "desc":"Interacting with multiple areas in the limbic system, the <strong>PFC</strong> (prefrontal cortex) manages emotional responses by modulating decision-making and attention. It can act directly upon areas such as the NAc to suppress emotional reactions. However, the PFC is suppressed by chronic exposure to stress hormone, leading to reduced thoughtful judgement, which can lead to impulsive behaviors. It is also important to note that the PFC has several subdivisions with unique functions. Particularly important for perception is the orbitofrontal cortex, which is activated when pleasing images are viewed. This suggests a role in aesthetic judgement that is more cognitively complex and goes beyond simple limbic reactions.<a href='https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0021852'> More info</a> ",
          "value": 7
        },

        {
          "valx": 5,
          "path":0,
          "valy" : 1,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 5,
          "path":0,
          "valy" : 2,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 7
        },
        {
          "valx": 5,
          "path":0,
          "valy" : 3,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 7
        },
         {
          "valx": 5,
          "path":0,
          "valy" : 4,
          "tLabel":"",
          "desc":"select a brain area",
          "value": 7
        },
        {
          "valx": 5,
          "path":7,
          "valy" : 5,
          "tLabel":"NAc",
          "desc":"The ‘reward center’ of the brain, the <strong>NAc</strong> (nucleus accumbens) takes dopaminergic inputs from the ventral tegmental area and is intune with sensory stimuli to help create a sense of pleasure and reward-learning. This area interacts extensively with the prefrontal cortex, in a battle between impulse and impulse control. This can go awry when stress hormones dampen the PFC, leading to an uninhibited NAc that can seek pleasure unrestrained. This is thought to be a reason why drug addiction or impulsive behaviors are more common in people who have been chronically under stress. But when well regulated, it can help the viewer to develop a liking for visual stimuli, drawing her to pleasant or rewarding aesthetics. It should be noted however that pleasant, rewarding, and beautiful are altogether not the same thing. It is still a challenge of research to discriminate between these and how they are processed by the brain. ",
          "value": 7
        },


        {
          "valx": 6,
          "path":7,
          "valy" : 6,
          "tLabel":"AMG",
"desc":"Responsible for giving emotional ‘color’ to visual stimuli, the <strong>AMG</strong> generally receives inputs directly from the hippocampus, thalamus, and sometimes the ventral stream  directly. The AMG is particularly important for generating fear responses, playing a role in fear learning and starting the chain of events leading to physiological ‘fight or flight’ responses via the hypothalamus. While visual stimuli will usually stimulate the AMG to generate emotional arousal, the prefrontal cortex can work to suppress these. However, some stimuli are processed more readily and it may be harder to control emotional reactions. For example, research has shown that fearful faces, and not fearful scenes or emotional faces, elicit extremely fast amygdalar responses via magnocellular pathways. While reactions such as these may be more universal, others are context-based and require inputs from the HPC or cortical areas, drawing on past memories. These emotional reactions help the viewer to create feeling around an experience, motivating behavior and creating narrative to go with visual experience. <a href='https://www.nature.com/articles/nn.4324'> More info</a> ",
          "value": 7.5
        },
        {
          "valx": 1,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 2,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 3,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 4,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 5,
          "path":7,
          "valy" : 6,
          "tLabel":"IC",
"desc":"Another important area is the <strong>IC</strong> (insular cortex) which connects both with the limbic and mirror neuron systems. Here corporeal experience (interoception), conscious desires, and social emotions (e.g. romantic love) are processed and observed in others to help form empathy. The IC is particularly good at reading and creating social emotion (e.g. empathy) because it can relay information between emotional centers for the viewer and mirror neurons that infer motivation and intention from others. ",
          "value": 7.5
        },
        {
          "valx": 6,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 6,
          "path":0,
          "valy" : 2,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 7
        },
        {
          "valx": 6,
          "path":0,
          "valy" : 3,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 7.6
        },
        {
          "valx": 6,
          "path":9.7,
          "valy" : 4,
          "tLabel":"B44",
          "desc":"Mirror neuron action can be observed in some portions of area <strong>B44</strong> (Brodmann 44), which overlaps with many brain regions, including Broca’s area (language processing). B44 works directly with the STS and PPC to understand the underlying goals of an action.",
          "value": 7.4
        },
        {
          "valx": 6,
          "path":8.2,
          "valy" : 5,

          "tLabel":"STS",
"desc":"The <strong>STS</strong> (superior temporal sulcus) receives inputs from both the ventral and dorsal streams in order to begin processing corporeal motion and goal directed behaviors. As the first stop in the ‘intentional’ loop, it integrates visual and other stimuli depending on the task in order to help with social perception (e.g. human voices, facial expressions etc.). It is also thought that it may play a role in the execution of behaviors, despite not having any motor neurons.<a href='https://doi.org/10.1073/pnas.241474598'> More info</a> & <a href='https://www.ncbi.nlm.nih.gov/pubmed/18457502'>Even more</a> ",
          "value": 7.6
        },


        {
          "valx": 7,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 8.5
        },
        {
          "valx": 7,
          "path":0,
          "valy" : 6,
          "tLabel":"",
"desc":"The <strong>IT</strong> (inferotemporal cortex) is the final leg of the ventral stream. This brain region processes visual information at the highest level of complexity. Instead of discerning individual edges, colors, and features, the IT identifies unified forms. Within the IT there are some areas that are specialized for the processing of specific forms. Of particular interest are the fusiform face area, focusing on recognition of people, and the parahippocampal place area, which assess objects and scenes broadly. These specialized areas focus on particularly important stimuli, possibly lending evolutionary advantages. The parahippocampal place area for example reacts strongly in assessing landscapes, communicating with pleasure centers and becoming particularly active when viewing ‘universally’ attractive landscapes. Because almost all people find similar savannah-like scenes attractive, some researchers conclude that this brain area evolved in Africa to draw us to fruitful and safe landscapes (coined the ‘Savannah Hypothesis’). More broadly, the IT’s architectonic zone temporal area E (TE) serves as the final stop for exclusively visual processing. Here, image evaluation is no longer retinotopic and instead relies on large receptive fields to help process scenes and complex objects. From the TE, visual information travels all across the brain, including limbic structures and cortical areas. <a href='https://doi.org/10.1016/j.visres.2008.04.015'> More info</a>",
          "value": 8.5
        },
        {
          "valx": 7,
          "path":7,
          "valy" : 5,
          "tLabel":"HPC",
          "desc":"Central the limbic system, or the ‘visceral brain’ (coined by MacLean) is the <strong>HPC</strong> (hippocampus). It is generally understood to be important for spatial and declarative memory (i.e. facts and conscious events) formation, but also interacts with several key areas. Inputs from the ventral and dorsal streams enter the hippocampus via extra-hippocampal cortices, where memory encoding begins. Memory formation is a complex process that is largely constructive (building from perceptions) and relies heavily on sleep. Different types of cells within the hippocampus work on different types of memory and will respond differently to sleep cycles. One example is place field cells, which will act like a map of a familiar place, each cell firing for a specific relative location within a space. Once sensory information flows through the HPC, it can be integrated into cortical areas as stored memories and used to shape emotional responses. Context is often important in shaping emotional responses, so memory helps to modulate amygdalar and hypothalamic responses. The hypothalamus acts as the gate to physiological responses to emotional inputs, and acts in accordance with the AMG and HPC.  ",
          "value": 8
        },
        {
          "valx": 7,
          "path":0.9,
          "valy" : 4,
          "tLabel":"LGN",
"desc":"After leaving the eyes, information is transmitted to the superior colliculus and the <strong>LGN</strong> (lateral geniculate nucleus). Taking only about 10% of the neural data, the SC connects to parietal and motor areas in the brain, playing a significant role in gaze orientation. Beyond helping to shift attention, it is not directly connected to the process of perception. Instead the LGN, which sits in the thalamus, receives the bulk of the retinal input onto cells that are organized retinotopically, reflecting the organization of the cells on the retina. In addition, the LGN contains parvo- and magnocellular tissue that receive input from ganglionic p- and m-cells respectively. The parvocellular tissues react to sustained stimuli and project information that will be used to define features. Conversely, the magnocellular tissues react to shorter bursts of stimulation, transmitting information related to motion. This LGN tissues are also organized by layers, with parvocellular tissues making up layers 3, 4, 5 and 6, and magnocellular only 1 and 2. Moreover, layers 2, 3, and 5 are ipsilateral layers, receiving inputs from the eye that is on the same side as the portion of the LGN. Layers 1, 2, 4, and 6 are contralateral, receiving inputs from the opposite eye. There are also koniocellular tissues whose role is still largely unclear. Essentially, the role of the LGN is to integrate visual information from both eyes and organize it to be processed by the downstream regions. ",
          "value": 8.1
        },
        {
          "valx": 7,
          "path":0,
          "valy" : 3,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 7.9
        },
        {
          "valx": 7,
          "path":0,
          "valy" : 2,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 7
        },
        {
          "valx": 7,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },

        {
          "valx": 6,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 7.8
        },
        {
          "valx": 5,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 4,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 3,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 2,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 1,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },

        {
          "valx": 8,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 8,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 9
        },
        {
          "valx": 8,
          "path":3.0,
          "valy" : 6,
          "tLabel":"IT",
"desc":"The <strong>IT</strong> (inferotemporal cortex) is the final leg of the ventral stream. This brain region processes visual information at the highest level of complexity. Instead of discerning individual edges, colors, and features, the IT identifies unified forms. Within the IT there are some areas that are specialized for the processing of specific forms. Of particular interest are the fusiform face area, focusing on recognition of people, and the parahippocampal place area, which assess objects and scenes broadly. These specialized areas focus on particularly important stimuli, possibly lending evolutionary advantages. The parahippocampal place area for example reacts strongly in assessing landscapes, communicating with pleasure centers and becoming particularly active when viewing ‘universally’ attractive landscapes. Because almost all people find similar savannah-like scenes attractive, some researchers conclude that this brain area evolved in Africa to draw us to fruitful and safe landscapes (coined the ‘Savannah Hypothesis’). More broadly, the IT’s architectonic zone temporal area E (TE) serves as the final stop for exclusively visual processing. Here, image evaluation is no longer retinotopic and instead relies on large receptive fields to help process scenes and complex objects. From the TE, visual information travels all across the brain, including limbic structures and cortical areas.<a href='https://doi.org/10.1152/jn.00696.2003'> More info</a>",
          "value": 8.7
        },
        {
          "valx": 8,
          "path":4.4,
          "valy" : 5,
          "tLabel":"MST & MT",
"desc":"The <strong>MST</strong> (middle superior temporal area) and <strong>MT</strong> (middle temporal area) are the first areas along the dorsal ‘where’ pathway, responsible for motion detection. First, inputs enter the MT, where basic motion cues such as speed, direction, and spatial/temporal frequency. The MST then refines those simple perceptions into complex ones, such as contractions, expansions, rotations, and others. Here optical flow begins to be perceived as object movement is becoming more whole, but is only partial.<a href='https://doi.org/10.1016/j.visres.2008.04.015'> More info</a>",
          "value": 8.5
        },
        {
          "valx": 8,
          "path":4.7,
          "valy" : 4,
          "tLabel":"PC",
"desc":"After leaving the temporal area (MT & MST), the relation between a moving environment and the viewer is solidified. Through the action of the <strong>PC</strong> (parietal cortex), the viewer is able to orient herself within the environment, fully perceiving optic flow and self-motion. Areas within this cortex, such as the LIP (lateral intraparietal area), which is responsible for spatial location and eye movement, will interact with areas in the ventral stream (parahippocampal place area in the IT).",
          "value": 8.5
        },
        {
          "valx": 8,
          "path":0,
          "valy" : 3,
          "tLabel":"",
"desc":"After leaving the temporal area (MT & MST), the relation between a moving environment and the viewer is solidified. Through the action of the <strong>PC</strong> (parietal cortex), the viewer is able to orient herself within the environment, fully perceiving optic flow and self-motion. Areas within this cortex, such as the LIP (lateral intraparietal area), which is responsible for spatial location and eye movement, will interact with areas in the ventral stream (parahippocampal place area in the IT).",
          "value": 8
        },
        {
          "valx": 8,
          "path":0,
          "valy" : 2,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 7.8
        },
        {
          "valx": 8,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },

        {
          "valx": 7,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 6,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 5,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 4,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 3,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 2,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 1,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
/*
        {
          "valx": 9,
          "path":0,
          "valy" : 9,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        */
        {
          "valx": 9,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 9,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 10
        },
        {
          "valx": 9,
          "path":2.5,
          "valy" : 6,
          "tLabel":"V4",
          "value": 9,
          "desc":"Responsible primarily for color and complex shape perception, the <strong>V4</strong> is the first step along the ventral stream. It is particularly specialized to perceive radial forms, angles, and curves. This area also plays a key role in creating selective attention to elements that have been deemed relevant. V4 firing rates decrease when unimportant stimuli are attended to, helping to dictate what is worthy of the viewers attention when the world is full of visual stimuli. It is also the beginning of idiosyncratic and adaptive visual perception, whereas V1 and V2 perception is rather simple and universal. For example, someone living in a large city is more visually adapted to the tall edges of buildings and will more readily ignore these using the selective attention and adaptive perception of her V4.<a href='https://doi.org/10.1126/science.4023713'> More info</a>"
        },
        {
          "valx": 9,
          "path":1.9,
          "valy" : 5,
          "tLabel":"V2",
"desc":"At the <strong>V2</strong> (visual area 2) the information processed at the V1 is refined in parallel, responding to more complex patterns. Building on V1 perception of edges, V2 processes contours at a higher level, including illusory lines and edges. This allows the viewer to ‘see’ boundaries and objects that have no physical reality. It also suggests a degree of flexibility regarding what is a perceivable contour. Some research suggests that the V2 sends information to the lateral occipital cortex, allowing the viewer to perceive shapes irrespective of how contours are defined. <a href='https://doi.org/10.1126/science.1061133'>More info</a>",
          "value": 8.7
        },
        {
          "valx": 9,
          "path":9,
          "valy" : 4,
          "tLabel":"PPC",
"desc":"Visual information can flow to the <strong>PPC</strong> (posterior parietal cortex) where a great deal of sensory information is integrated and is particularly active for both the observation and execution of biological action. This is done by taking in information from the STS in order to create cognitive parallels between sensory information and action (underlying imitation).",
          "value": 8.4
        },
        {
          "valx": 9,
          "path": 0,
          "valy" : 3,
          "tLabel":"",
"desc":"After leaving the temporal area (MT & MST), the relation between a moving environment and the viewer is solidified. Through the action of the <strong>PC</strong> (parietal cortex), the viewer is able to orient herself within the environment, fully perceiving optic flow and self-motion. Areas within this cortex, such as the LIP (lateral intraparietal area), which is responsible for spatial location, will interact with areas in the ventral stream (parahippocampal place area in the IT).",
          "value": 8.3
        },
        {
          "valx": 9,
          "path":0,
          "valy" : 2,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 9,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },

        {
          "valx": 10,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 10,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 10,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 9
        },
        {
          "valx": 10,
          "path":1.5,
          "valy" : 5,
          "tLabel":"V1",
"desc":"After integrating the visual information, the LGN transmits its rudimentary image to the much larger <strong>V1</strong> (visual area 1) of the striate cortex, where perception of an image actually begins. This structure is retinotopic like the LGN and preferentially processes foveal information by having a high ratio of cells receiving inputs from the relatively small fovea on the retina(cortical magnification). Because of this it is much easier to process visual information that is looked at directly, rather than peripherally. Another important feature of the V1 is that is organized into hypercolumns within its layers with cells that respond to specific orientations of forms. Within the columns, simple cortical cells with center-surround organization similar to that on the retina discern not only orientation, but detect edges and lines. Further downstream there are complex cortical cells that are particularly receptive to motion and nonlinear forms, able to detect more complex features using larger receptive fields. Finally, end stopped cells combine both elements, activating in response to moving lines and corners. At the V1, color begins to be detected, but is not highly processed. It is also believed that through V1 activity, selective attention to certain features can help in searching. ",
          "value": 9
        },
        {
          "valx": 10,
          "path":0,
          "valy" : 4,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 9
        },
        {
          "valx": 10,
          "path":0,
          "valy" : 3,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 10,
          "path":0,
          "valy" : 2,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 10,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },


/*buffer*/



        {
          "valx": 11,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 11,
          "path":0,
          "valy" : 2,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 11,
          "path":0,
          "valy" : 3,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 11,
          "path":0,
          "valy" : 4,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 11,
          "path":0,
          "valy" : 5,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 11,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 11,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 11,
          "path":0,
          "valy" : 8,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },


        {
          "valx": 17,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 18,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 19,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 20,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 21,
          "path":0,
          "valy" : 7,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },


        {
          "valx": 17,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 18,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 19,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 20,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 21,
          "path":0,
          "valy" : 1,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },









     {
          "valx": 17,
          "path":0.1,
          "valy" : 2,
          "tLabel":"Retina",
          "desc":"Light first enters the eye through the cornea and strikes the <strong>retina</strong>, beginning the phototransduction process of turning external light energy into electrical energy. Rod cells (for color perception) and cone cells (for value perception) on the retina absorb the light using rhodopsin proteins to hyperpolarize the cells’ internal charge. Sharpness of perceived images is maintained by concentrating rod cells at the fovea in the back of the eye. Additionally, a background layer of cells, the pigmented epithelium, absorbs unprocessed light. The electrical signals are then converted to glutaminergic messages passed to bipolar, then ganglion cells. Horizontal and amacrine cells act as mediators between each respective layer of transmission to further sharpen the image. These mediators work on the principle that retinal cells are organized in concentric receptive fields, creating a map of “on” and “off” center cells, becoming active depending on their relative positions. The mediators horizontally cancel noise, amplifying these place field maps. From there, downstream ganglion cells themselves are divided into groups of either m- or p-cells, providing unique information to later on dorsal and ventral streams. From there, the neural image travels down the optic nerve, past the chiasm where the images from each receptive field (right and left) are directed to their respective hemispheres.  ",
          "value": 1
        },
        {
          "valx": 17,
          "path":0.9,
          "valy" : 3,
          "tLabel":"LGN",
"desc":"After leaving the eyes, information is transmitted to the superior colliculus and the <strong>LGN</strong> (lateral geniculate nucleus). Taking only about 10% of the neural data, the SC connects to parietal and motor areas in the brain, playing a significant role in gaze orientation. Beyond helping to shift attention, it is not directly connected to the process of perception. Instead the LGN, which sits in the thalamus, receives the bulk of the retinal input onto cells that are organized retinotopically, reflecting the organization of the cells on the retina. In addition, the LGN contains parvo- and magnocellular tissue that receive input from ganglionic p- and m-cells respectively. The parvocellular tissues react to sustained stimuli and project information that will be used to define features. Conversely, the magnocellular tissues react to shorter bursts of stimulation, transmitting information related to motion. This LGN tissues are also organized by layers, with parvocellular tissues making up layers 3, 4, 5 and 6, and magnocellular only 1 and 2. Moreover, layers 2, 3, and 5 are ipsilateral layers, receiving inputs from the eye that is on the same side as the portion of the LGN. Layers 1, 2, 4, and 6 are contralateral, receiving inputs from the opposite eye. There are also koniocellular tissues whose role is still largely unclear. Essentially, the role of the LGN is to integrate visual information from both eyes and organize it to be processed by the downstream regions. ",
          "value": 1
        },
        {
          "valx": 17,
          "path":1.5,
          "valy" : 4,
          "tLabel":"V1",
"desc":"After integrating the visual information, the LGN transmits its rudimentary image to the much larger <strong>V1</strong> (visual area 1) of the striate cortex, where perception of an image actually begins. This structure is retinotopic like the LGN and preferentially processes foveal information by having a high ratio of cells receiving inputs from the relatively small fovea on the retina(cortical magnification). Because of this it is much easier to process visual information that is looked at directly, rather than peripherally. Another important feature of the V1 is that is organized into hypercolumns within its layers with cells that respond to specific orientations of forms. Within the columns, simple cortical cells with center-surround organization similar to that on the retina discern not only orientation, but detect edges and lines. Further downstream there are complex cortical cells that are particularly receptive to motion and nonlinear forms, able to detect more complex features using larger receptive fields. Finally, end stopped cells combine both elements, activating in response to moving lines and corners. At the V1, color begins to be detected, but is not highly processed. It is also believed that through V1 activity, selective attention to certain features can help in searching. ",
          "value": 1,
        },
        {
          "valx": 17,
          "path":1.9,
          "valy" : 5,
          "tLabel":"V2",
"desc":"At the <strong>V2</strong> (visual area 2) the information processed at the V1 is refined in parallel, responding to more complex patterns. Building on V1 perception of edges, V2 processes contours at a higher level, including illusory lines and edges. This allows the viewer to ‘see’ boundaries and objects that have no physical reality. It also suggests a degree of flexibility regarding what is a perceivable contour. Some research suggests that the V2 sends information to the lateral occipital cortex, allowing the viewer to perceive shapes irrespective of how contours are defined. <a href='https://doi.org/10.1126/science.1061133'>More info</a>",
          "value": 1
        },
        {
          "valx": 17,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 18,
          "path":4.2,
          "valy" : 2,
          "tLabel":"MST & MT",
"desc":"The <strong>MST</strong> (middle superior temporal area) and <strong>MT</strong> (middle temporal area) are the first areas along the dorsal ‘where’ pathway, responsible for motion detection. First, inputs enter the MT, where basic motion cues such as speed, direction, and spatial/temporal frequency. The MST then refines those simple perceptions into complex ones, such as contractions, expansions, rotations, and others. Here optical flow begins to be perceived as object movement is becoming more whole, but is only partial.<a href='https://doi.org/10.1016/j.visres.2008.04.015'> More info</a>",
          "value": 1
        },
        {
          "valx": 18,
           "path":4.5,
          "valy" : 3,
          "tLabel":"PC",
"desc":"After leaving the temporal area (MT & MST), the relation between a moving environment and the viewer is solidified. Through the action of the <strong>PC</strong> (parietal cortex), the viewer is able to orient herself within the environment, fully perceiving optic flow and self-motion. Areas within this cortex, such as the LIP (lateral intraparietal area), which is responsible for spatial location and eye movement, will interact with areas in the ventral stream (parahippocampal place area in the IT).",
          "value": 1
        },
        {
          "valx": 18,
          "path":0,
          "valy" : 4,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 18,
          "path":0,
          "valy" : 5,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 18,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1},
        {
          "valx": 19,
          "path":2.15,
          "valy" : 2,
          "tLabel":"V4",
          "value": 9,
          "desc":"Responsible primarily for color and complex shape perception, the <strong>V4</strong> is the first step along the ventral stream. It is particularly specialized to perceive radial forms, angles, and curves. This area also plays a key role in creating selective attention to elements that have been deemed relevant. V4 firing rates decrease when unimportant stimuli are attended to, helping to dictate what is worthy of the viewers attention when the world is full of visual stimuli. It is also the beginning of idiosyncratic and adaptive visual perception, whereas V1 and V2 perception is rather simple and universal. For example, someone living in a large city is more visually adapted to the tall edges of buildings and will more readily ignore these using the selective attention and adaptive perception of her V4.<a href='https://doi.org/10.1126/science.4023713'> More info</a>",
          "value": 1
        },
        {
          "valx": 19,
          "path": 2.5,
          "valy" : 3,
          "tLabel":"IT",
"desc":"The <strong>IT</strong> (inferotemporal cortex) is the final leg of the ventral stream. This brain region processes visual information at the highest level of complexity. Instead of discerning individual edges, colors, and features, the IT identifies unified forms. Within the IT there are some areas that are specialized for the processing of specific forms. Of particular interest are the fusiform face area, focusing on recognition of people, and the parahippocampal place area, which assess objects and scenes broadly. These specialized areas focus on particularly important stimuli, possibly lending evolutionary advantages. The parahippocampal place area for example reacts strongly in assessing landscapes, communicating with pleasure centers and becoming particularly active when viewing ‘universally’ attractive landscapes. Because almost all people find similar savannah-like scenes attractive, some researchers conclude that this brain area evolved in Africa to draw us to fruitful and safe landscapes (coined the ‘Savannah Hypothesis’). More broadly, the IT’s architectonic zone temporal area E (TE) serves as the final stop for exclusively visual processing. Here, image evaluation is no longer retinotopic and instead relies on large receptive fields to help process scenes and complex objects. From the TE, visual information travels all across the brain, including limbic structures and cortical areas.<a href='https://doi.org/10.1152/jn.00696.2003'> More info</a>",
          "value": 1
        },
        {
          "valx": 19,
          "path":0,
          "valy" : 4,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 19,
          "path":0,
          "valy" : 5,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 19,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1},
          {
          "valx": 20,
          "path":8.2,
          "valy" : 2,
          "tLabel":"STS",
"desc":"The <strong>STS</strong> (superior temporal sulcus) receives inputs from both the ventral and dorsal streams in order to begin processing corporeal motion and goal directed behaviors. As the first stop in the ‘intentional’ loop, it integrates visual and other stimuli depending on the task in order to help with social perception (e.g. human voices, facial expressions etc.). It is also thought that it may play a role in the execution of behaviors, despite not having any motor neurons.<a href='https://doi.org/10.1073/pnas.241474598'> More info</a> & <a href='https://www.ncbi.nlm.nih.gov/pubmed/18457502'>Even more</a> ",
          "value": 1
        },
        {
          "valx": 20,
          "path":8.7,
          "valy" : 3,
          "tLabel":"PPC",
"desc":"Visual information can flow to the <strong>PPC</strong> (posterior parietal cortex) where a great deal of sensory information is integrated and is particularly active for both the observation and execution of biological action. This is done by taking in information from the STS in order to create cognitive parallels between sensory information and action (underlying imitation).",
          "value": 1
        },
        {
          "valx": 20,
          "path":9.4,
          "valy" : 4,
          "tLabel":"B44",
          "desc":"Mirror neuron action can be observed in some portions of area <strong>B44</strong> (Brodmann 44), which overlaps with many brain regions, including Broca’s area (language processing). B44 works directly with the STS and PPC to understand the underlying goals of an action.",
          "value": 1
        },
        {
          "valx": 20,
          "path":0,
          "valy" : 5,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        },
        {
          "valx": 20,
          "path":0,
          "valy" : 6,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1},
{
          "valx": 21,
           "path":7,
          "valy" : 2,
          "tLabel":"HPC",
          "desc":"Central the limbic system, or the ‘visceral brain’ (coined by MacLean) is the <strong>HPC</strong> (hippocampus). It is generally understood to be important for spatial and declarative memory (i.e. facts and conscious events) formation, but also interacts with several key areas. Inputs from the ventral and dorsal streams enter the hippocampus via extra-hippocampal cortices, where memory encoding begins. Memory formation is a complex process that is largely constructive (building from perceptions) and relies heavily on sleep. Different types of cells within the hippocampus work on different types of memory and will respond differently to sleep cycles. One example is place field cells, which will act like a map of a familiar place, each cell firing for a specific relative location within a space. Once sensory information flows through the HPC, it can be integrated into cortical areas as stored memories and used to shape emotional responses. Context is often important in shaping emotional responses, so memory helps to modulate amygdalar and hypothalamic responses. The hypothalamus acts as the gate to physiological responses to emotional inputs, and acts in accordance with the AMG and HPC.  ",
          "value": 1
        },
        {
          "valx": 21,
          "path":7,
          "valy" : 3,
          "tLabel":"AMG",
"desc":"Responsible for giving emotional ‘color’ to visual stimuli, the <strong>AMG</strong> generally receives inputs directly from the hippocampus, thalamus, and sometimes the ventral stream  directly. The AMG is particularly important for generating fear responses, playing a role in fear learning and starting the chain of events leading to physiological ‘fight or flight’ responses via the hypothalamus. While visual stimuli will usually stimulate the AMG to generate emotional arousal, the prefrontal cortex can work to suppress these. However, some stimuli are processed more readily and it may be harder to control emotional reactions. For example, research has shown that fearful faces, and not fearful scenes or emotional faces, elicit extremely fast amygdalar responses via magnocellular pathways. While reactions such as these may be more universal, others are context-based and require inputs from the HPC or cortical areas, drawing on past memories. These emotional reactions help the viewer to create feeling around an experience, motivating behavior and creating narrative to go with visual experience. <a href='https://www.nature.com/articles/nn.4324'> More info</a> ",
          "value": 1
        },
        {
          "valx": 21,
          "path":7,
          "valy" : 4,
          "tLabel":"NAc",
          "desc":"The ‘reward center’ of the brain, the <strong>NAc</strong> (nucleus accumbens) takes dopaminergic inputs from the ventral tegmental area and is intune with sensory stimuli to help create a sense of pleasure and reward-learning. This area interacts extensively with the prefrontal cortex, in a battle between impulse and impulse control. This can go awry when stress hormones dampen the PFC, leading to an uninhibited NAc that can seek pleasure unrestrained. This is thought to be a reason why drug addiction or impulsive behaviors are more common in people who have been chronically under stress. But when well regulated, it can help the viewer to develop a liking for visual stimuli, drawing her to pleasant or rewarding aesthetics. It should be noted however that pleasant, rewarding, and beautiful are altogether not the same thing. It is still a challenge of research to discriminate between these and how they are processed by the brain. ",
          "value": 1
        },
        {
          "valx": 21,
          "path":7,
          "valy" : 5,
          "tLabel":"IC",
"desc":"Another important area is the <strong>IC</strong> (insular cortex) which connects both with the limbic and mirror neuron systems. Here corporeal experience (interoception), conscious desires, and social emotions (e.g. romantic love) are processed and observed in others to help form empathy. The IC is particularly good at reading and creating social emotion (e.g. empathy) because it can relay information between emotional centers for the viewer and mirror neurons that infer motivation and intention from others. ",
          "value": 1
        },
        {
          "valx": 21,
            "path":7,
          "valy" : 6,
          "tLabel":"PFC",
          "desc":"Interacting with multiple areas in the limbic system, the <strong>PFC</strong> (prefrontal cortex) manages emotional responses by modulating decision-making and attention. It can act directly upon areas such as the NAc to suppress emotional reactions. However, the PFC is suppressed by chronic exposure to stress hormone, leading to reduced thoughtful judgement, which can lead to impulsive behaviors. It is also important to note that the PFC has several subdivisions with unique functions. Particularly important for perception is the orbitofrontal cortex, which is activated when pleasing images are viewed. This suggests a role in aesthetic judgement that is more cognitively complex and goes beyond simple limbic reactions.<a href='https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0021852'> More info</a> ",
          "value": 1
        },
        {
          "valx": 20,
          "path":0,
          "valy" : 5,
          
"tLabel":" ",
"desc":"select a brain area",
          "value": 1
        }





    ];











var marginsh = {top:20, right:110, bottom:165, left:60}
var svgWidthh = 660;
var svgHeighth = 330;




var colorScale = d3.scaleLinear()
    .domain([1,7])
    //#FFC0CB
    .range(["#fcf1eb","#ff7575"]);

var perceptualScale = d3.scaleLinear()
    .domain([0,2])
    .range(["#32CD00","yellow"]);

var ventralScale = d3.scaleLinear()
    .domain([2,4])
    .range(["yellow","red"]);

var dorsalScale = d3.scaleLinear()
    .domain([4,6])
    .range(["yellow","red"]);

var meaningfulScale = d3.scaleLinear()
    .domain([5,7])
    .range(["red","red"]);

var intentionalScale = d3.scaleLinear()
    .domain([8,10])
    .range(["orange","red"]);

var totalScale = d3.scaleLinear()
    .domain([0,10])
    .range(["#E3FF00","red"]);

var svgh = d3.select(".grid")
    .append("svg")
    .attr("width", svgWidthh)
    .attr("height", svgHeighth)
    .attr("transform", "translate(0," + '-240' + ")");

 tooltip=d3.select("body")
 .append("div")
 .style("width","40px")
 .style("height","40px")
 .style("background","rgba(0,0,0,0")
  .style("opacity","1")
  .style("position","absolute")
  .style("padding","10px");
    toolval=tooltip.append("div");

var rects = svgh.selectAll(".rectGroup")
    .data(datah)
    .enter()
    .append("g")
    .append("rect")
    .attr("x", function(d){
      return (d.valx * 30-30);

    })
    .attr("y", function(d){
      return (d.valy * 30-30);
    })
    .attr("width", 30)
    .attr("height", 30)
    .style("fill", function(d){
      return colorScale(d.value);
    })



    .on("mouseover",function(d){
      d3.select(this)
      .style("opacity","0.5");
    })

    .on("mouseout",function(d){
      d3.select(this)
      .style("opacity","1");
    })



    .on("click", function(d){
      d3.select("#brainarea")
      .html(d.desc)
      ;


    })

    .on("mousemove",function(d){
            tooltip.style("top",(d3.event.pageY-15)+"px")
            .style("left",(d3.event.pageX+7)+"px");
            tooltip.select("div")
            .html("<strong>"+d.tLabel+"</strong>")
            .style("opacity", "1")

        })


    .on("mouseleave",function(d){
        tooltip.style("top",(d3.event.pageY-15)+"px")
            .style("left",(d3.event.pageX+7)+"px");
            tooltip.select("div")
            .style("opacity", "0")

    });


  //      function resetFunction() {
  //        rects.style("fill", function(d){
  //     return colorScale(d.value);
  //      });
  //       var selection = rects.filter(function(dd) { console.log(dd); return dd.path > 1 && dd.path < 10 ; });
  // selection.each(function(d){
  //   svgh.selectAll("text")
  //   .remove()
  //   })
  //      }


/*d3.select("#n1").on("click", function() {
  rects.style("fill", function(d){
    var selection = rects.filter(function(d) {
      console.log(d);

      selection.style("fill",function(d){
      return perceptualScale(d.path);
    });
return colorScale(d.value);
})
  d3.select("#description")
    .html("Vision begins with an image, light photons, entering the eye through the cornea and lens, where the image is inverted and refracted onto the back of the eye, the <strong>retina</strong>. On the retina a layer of receptive cells convert the light into electrical messages  through a process called phototransduction. Rod cells on the retina absorb the light indiscriminately, transmitting the intensity (brightness), while cone cells will absorb various colors of light. The generated charge moves from cell to cell via chemical neurotransmitters down several layers of cells, down the optic nerve, and eventually to the <strong>LGN</strong> (lateral geniculate nucleus), where the information is integrated. This means that the information from both eyes is mapped together onto cells on the LGN to form a cohesive image. It is also the first step to move from simple reception of stimuli to cognitive perception, where images are interpreted by the brain. In the next step, that basic image is transmitted to the striate cortex, or the <strong>V1</strong> (primary visual cortex). At the V1, the image begins to be refined as elements like orientation of forms and contrast are discerned. From here the information moves to the extrastriate cortex, stopping first at the <strong>V2</strong>, where perception of contours and edges is further refined. Of course other brain areas are involved in the first steps of vision, but these are the main components that lay out the map for a viewed image to be processed and perceived. For example, one brain area, the superior colliculus, which receives a small amount of visual input at this stage, will help dictate eye movements and how to allocate attention. However, it does not contribute significantly to the process of perception. It should be noted that perception is not meant to mean simply seeing, but a constructive process whereby simple, visual information is turned into complex, cognitive information, shaped by the consciousness of the viewer (i.e. bias, memories, expectations etc.). This is to say two people will perceive the same painting differently based on individual differences in their minds, even though they are looking at the same image. <a href='https://doi.org/10.1016/B978-1-4377-1926-0.10013-X'>more info</a>");

});*/

d3.select("#n1").on("click", function() {

    
        var allSelection = rects.filter(function(dd) { console.log(dd); return dd.path > 0 && dd.path < 10 ; });
        allSelection.each(function(d){
            svgh.selectAll("text")
                .remove()
        })

        var selection = rects.filter(function(d) { console.log(d); return d.path > 0 && d.path < 2 ; });
        selection.each(function(d) {
            svgh.append("text")
                .attr("x", function(){
                    return (d.valx * 30)-15;

                })
                .attr("y", function(){
                    return (d.valy * 30)-10;
                })
                .style("fill","black")
                .style("font-weight","bold")
                .style('font-size', '13px')
                .text(d.tLabel)
                .raise();
        })
        rects.style("fill", function(d){
        selection.style("fill",function(d){
            return perceptualScale(d.path);
        });
        return colorScale(d.value);
    })
    d3.select("#description")
        .html("<strong>Perceptual</strong> <br> Vision begins with an image, light photons, entering the eye through the cornea and lens, where the image is inverted and refracted onto the back of the eye, the <strong>retina</strong>. On the retina a layer of receptive cells convert the light into electrical messages  through a process called phototransduction. Rod cells on the retina absorb the light indiscriminately, transmitting the intensity (brightness), while cone cells will absorb various colors of light. The generated charge moves from cell to cell via chemical neurotransmitters down several layers of cells, down the optic nerve, and eventually to the <strong>LGN</strong> (lateral geniculate nucleus), where the information is integrated. This means that the information from both eyes is mapped together onto cells on the LGN to form a cohesive image. It is also the first step to move from simple reception of stimuli to cognitive perception, where images are interpreted by the brain. In the next step, that basic image is transmitted to the striate cortex, or the <strong>V1</strong> (primary visual cortex). At the V1, the image begins to be refined as elements like orientation of forms and contrast are discerned. From here the information moves to the extrastriate cortex, stopping first at the <strong>V2</strong>, where perception of contours and edges is further refined. Of course other brain areas are involved in the first steps of vision, but these are the main components that lay out the map for a viewed image to be processed and perceived. For example, one brain area, the superior colliculus, which receives a small amount of visual input at this stage, will help dictate eye movements and how to allocate attention. However, it does not contribute significantly to the process of perception. It should be noted that perception is not meant to mean simply seeing, but a constructive process whereby simple, visual information is turned into complex, cognitive information, shaped by the consciousness of the viewer (i.e. bias, memories, expectations etc.). This is to say two people will perceive the same painting differently based on individual differences in their minds, even though they are looking at the same image. <a href='https://doi.org/10.1016/B978-1-4377-1926-0.10013-X'>more info</a>");

});



d3.select("#n2")
    .on("click", function(){
        

            var allSelection = rects.filter(function(dd) { console.log(dd); return dd.path > 0 && dd.path < 10 ; });
            allSelection.each(function(d){
                svgh.selectAll("text")
                    .remove()
            })

            var selection = rects.filter(function(d) { console.log(d); return d.path > 2.1 && d.path < 4.1 ; });
            selection.each(function(d) {
                svgh.append("text")
                    .attr("x", function(){
                        return (d.valx * 30)-15;

                    })
                    .attr("y", function(){
                        return (d.valy * 30)-10;
                    })
                    .style("fill","black")
                    .style("font-weight","bold")
                    .style('font-size', '13px')
                    .text(d.tLabel)
                    .raise();
            })
            rects.style("fill", function(d){
            selection.style("fill",function(d){
                return ventralScale(d.path);
            });
            return colorScale(d.value);
        })
        d3.select("#description")
            .html("<strong>Ventral</strong> <br> After basic forms are perceived, the image gets clearer as it flows down to the ‘ventral stream’ or the ‘what’ pathway. This pathway is responsible for identifying objects and discerning features. Information originating from parvocellular neurons lands here, leaving the V2 for the <strong>V4</strong> (visual area 4). V4 focuses on perceiving color, and processes more complex features, such as radial forms. The final stop for the ventral stream is the <strong>IT</strong> (inferotemporal cortex), which is responsible for higher level processing of images. This means processing images as whole objects and beginning to derive meaning, like identifying a car or seeing a smiling face. The primary areas are the TEO and TE, which are not retinotopic like previous areas and instead focus on objects and areas of interest in the visual field. Together, the V4 and IT play a key role in selective attention, filtering for relevant stimuli within receptive fields. Overall the ventral stream seeks to take basic cues about contours, spatial frequency, and color from the striate cortex (V1), and refine them so that features can be identified as objects.");


    });


d3.select("#n3").on("click", function() {

    
        var allSelection = rects.filter(function(dd) { console.log(dd); return dd.path > 0 && dd.path < 10 ; });
        allSelection.each(function(d){
            svgh.selectAll("text")
                .remove()
        })

        var selection = rects.filter(function(d) { console.log(d); return d.path > 3.9 && d.path < 6 ; });
        selection.each(function(d) {
            svgh.append("text")
                .attr("x", function(){
                    return (d.valx * 30)-15;

                })
                .attr("y", function(){
                    return (d.valy * 30)+-10;
                })
                .style("fill","black")
                .style("font-weight","bold")
                .style('font-size', '13px')
                .text(d.tLabel)
                .raise();
        })
        rects.style("fill", function(d){
        selection.style("fill",function(d){
            return dorsalScale(d.path);
        });

        return colorScale(d.value);
    })
    d3.select("#description")
        .html("<strong>Dorsal</strong> <br> Outputs leaving the striate cortex for the parietal lobe constitute the ‘dorsal stream,’ giving an image space, depth, and location. Unlike the ventral stream, information from ganglionic m-cells informs the dorsal stream, providing information on motion and space. The ‘where’ pathway moves neural information from the V2 to the <strong>MST</strong> (middle superior temporal area) and <strong>MT</strong> (middle temporal area), where motion is discriminated and perceived. The <strong>PC</strong> (parietal cortex) then receives this information and use its several sub-areas to construct a relationship between the environment and the viewer. Here the viewers body and point of view is understood in relation to the environment. This results in the phenomenon of “optical flow”, whereby the viewer gets the sense that the environment is moving relative to them. Moreover, the PC integrates stimuli with motor functions so that the viewer can interact with the environment, shifting her gaze or reaching for an object in space.  ");

});


d3.select("#n4").on("click", function() {

 
        var allSelection = rects.filter(function(dd) { console.log(dd); return dd.path > 0 && dd.path < 10 ; });
        allSelection.each(function(d){
            svgh.selectAll("text")
                .remove()
        })

        var selection = rects.filter(function(d) { console.log(d); return d.path > 6.1 && d.path < 8 ; });
        selection.each(function(d) {
            svgh.append("text")
                .attr("x", function(){
                    return (d.valx * 30)-15;

                })
                .attr("y", function(){
                    return (d.valy * 30)-10;
                })
                .style("fill","black")
                .style("font-weight","bold")
                .style('font-size', '13px')
                .text(d.tLabel)
                .raise();
        })
           rects.style("fill", function(d){
        selection.style("fill",function(d){
            return dorsalScale(d.path);
        });
        return colorScale(d.value);
    })
    d3.select("#description")
        .html("<strong>Meaningful</strong> <br> Beyond visual processing, brain areas in the limbic system and frontal lobe work to construct cognitive and emotional meaning using visual inputs. Information flows freely from one area to another, balancing emotional and cognitive reactions in the viewer. However, the first step is generally the <strong>HPC</strong> (hippocampus), which is largely responsible for autobiographical and spatial memory. Here visual data is contextualized within the subjective experience of the viewer. Once it is connected the the viewer, emotions are more easily assigned via the <strong>AMG</strong> (amygdala) and the <strong>NAc</strong> (nucleus accumbens), which are responsible for assigning emotional valence, and generating pleasure and motivation respectively. A consumer of dopamine, the NAc processes feelings of pleasure and motivates her to seek out those stimuli. The AMG also interacts directly with the ventral ‘what’ stream, allowing the viewer to make fast emotional reactions to objects and features (e.g. pleasure upon seeing a familiar face, fear of a snake, etc.). Particularly reactive to uncertainty and fearful imagery, the AMG also provides a connection to the endocrine system that will release stress hormones (cortisol). In the frontal lobe, the <strong>PFC</strong> (prefrontal cortex) will take inputs from all the above areas in order to inform decision-making and attention. These inputs come as stress, pleasure, contextualized visual information, and reward. The PFC can then feedback on these areas to suppress emotions or impulses and vice versa. Other areas in the frontal lobe, such as the <strong>OFC</strong> (orbitofrontal cortex) are tied to cognitive response to visual inputs that are evaluated to be pleasing, such as beautiful painting. Another important area is the <strong>IC</strong> (insular cortex) which context both with the limbic and mirror neuron systems. Here corporeal experience (interoception), conscious desires, and social emotions (e.g. romantic love) are processed and observed in others to help form empathy. Taken together, the brain works to contextualize and form adaptive responses to visual inputs. These responses are tempered by the personal experience of the viewer and are constructed, rather than simply reflecting an objective reality. ");

});



d3.select("#n5").on("click", function() {

    
        var allSelection = rects.filter(function(dd) { console.log(dd); return dd.path > 0 && dd.path < 10 ; });
        allSelection.each(function(d){
            svgh.selectAll("text")
                .remove()
        })

        var selection = rects.filter(function(d) { console.log(d); return d.path > 8.1 && d.path < 10 ; });
        selection.each(function(d) {
            svgh.append("text")
                .attr("x", function(){
                    return (d.valx * 30)-15;

                })
                .attr("y", function(){
                    return (d.valy * 30)-10;
                })
                .style("fill","black")
                .style("font-weight","bold")
                .style('font-size', '13px')
                .text(d.tLabel)
                .raise();
        })
        rects.style("fill", function(d){
        selection.style("fill",function(d){
            return intentionalScale(d.path);
        });
        return colorScale(d.value);
    })
    d3.select("#description")
        .html("<strong>Intentional</strong> <br> These brain areas are responsible for higher order visual processing, using mirror neurons to create and discern intention. This loop is particularly important because it receives a great deal inputs and has mirror neurons that activate under very specific conditions: (1) biological motion that explicitly entails perceived intention (e.g. a hand moving food toward a mouth) and (2) execution of intended actions. This dual action is thought to underlie responses such as empathy and help in creating ‘Theory of Mind.’ First the <strong>STS</strong> (superior temporal sulcus) receives inputs from both the ventral and dorsal stream in order to begin processing corporeal motion and goal directed behaviors. It is also thought that it may play a role in the execution of behaviors, despite not having any motor neurons. The information then flows to the <strong>PPC</strong> (posterior parietal cortex) where a great deal of sensory information is integrated and is particularly active for both the observation and execution of biological action. Mirror neuron action can be observed in area <strong>B44</strong> (Brodmann 44), which overlaps with many brain regions, including Broca’s area (language processing). Because we cannot read minds, behavior in others is used as a way to evaluate mental states. Areas outside of the mirror neuron loop then evaluate the ‘meaning’ of intention by guessing at outcomes of actions or feeling empathy. One critical area closely tied to the PPC, is the TPJ (Temporal Parietal Junction), which tries to understand intention by processing the motivation behind an observed action. In observing human forms, the brain intuitively looks for cues that imply intention and feeling, closing the gap between the observer and the subject.");

});
d3.select("#n6").on("click", function() {
  rects.style("fill", function(d){
      return colorScale(d.value);
       });
      var selection = rects.filter(function(dd) { console.log(dd); return dd.path > 1 && dd.path < 10 ; });
  selection.each(function(d){
    svgh.selectAll("text")
    .remove()
    });


  d3.select("#description")
    .html("select a pathway");
  d3.select("#brainarea")
  .html("select a brain area")
});




/*
var xScaleh = d3.scalePoint()
    .domain(datah.map(function(d){return d.aLabel;}))
    .range([marginsh.left+50, svgWidthh-marginsh.right]);

 /*var x_axish = d3.axisBottom()
    .scale(xScaleh);


var yScaleh = d3.scalePoint()
    .domain(datah.map(function(d){return d.tLabel;}))
    .range([marginsh.top+5, svgHeighth+50-(marginsh.bottom+35)]);

 var y_axish = d3.axisLeft()
    .scale(yScaleh);


svgh.append("g")
    .attr("transform", "translate("+ (marginsh.left) +","+ (marginsh.top - 10) +")")
    .call(y_axish)
    .attr("class","axisy");

svgh.append("g")
    .attr("transform", "translate(-10, " + (svgHeighth+50 - marginsh.bottom+18)  +")")
    .call(x_axish)
    .attr("class","axisx")
    .selectAll("text")
    .attr("y", 10)
    .attr("x", 9)
    .attr("transform", "rotate(45)")
    .attr("text-anchor", "start");
*/
